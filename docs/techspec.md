Ниже — **чисто алгоритмическое ТЗ** для модели, которая **не знает теории и физики**, и у неё есть только ROOT-файл. Делай ровно так: вход → потоковая обработка → матрицы/спектр/метрики → отчёт.

> Примечание: я обычно отдаю это ещё и архивом со скриптами/README, но сейчас инструмент упаковки у меня падает ошибкой, поэтому даю ТЗ полностью текстом (его можно прямо скопировать в задачу другой модели/исполнителю).

---

# ТЗ: обработка `Run2012BC_DoubleMuParked_Muons.root` (2 GB) без загрузки в память

## 0) Ограничения

* НЕЛЬЗЯ читать ROOT целиком в память.
* Обработка только **потоковая (chunked)**.
* Никаких предположений о физическом смысле веток.
* Выход должен быть **строго численным**: CSV/NPZ/JSON + краткий отчёт.

---

## 1) Вход

### Обязательный

* `input_root`: путь к ROOT-файлу.

### Опциональный конфиг (YAML)

* `tree`: имя TTree (если известно).
* `branches`: список веток (если задан — использовать его).
* `mode`: `quantile` или `zscore`.
* `bins`: число бинов (по умолчанию 16).
* `chunk`: размер чанка (по умолчанию 200000).
* `max_events`: 0 = все события.
* `tau`: порог для разреживания W (по умолчанию 0.1).
* `topk`: top-k рёбер на вершину (0 = выкл).
* `k_eigs`: сколько наименьших собственных значений искать (если матрица большая).
* `baseline`: true/false (делать контроль “без корреляций”).
* `seed`: целое.

**Дополнение (jagged-ветки):** см. `docs/addontspc.md`. При включении поддержки jagged-массивов в YAML задают: `allow_jagged`, `jagged_branches` (или null для авто), `jagged_aggs` (len, sum, mean, std, min, max, q25, median, q75, l2), `max_jagged_branches`, `max_scalar_branches`, при необходимости `max_scan`.

---

## 2) Обязательные выходы (файлы)

**Каждый запуск пишет в свой каталог:** выходы попадают в подкаталог с меткой времени запуска `YYYY-MM-DDThh_mm_ss` (локальное время). Базовый путь задаётся через `--out` (по умолчанию `data/out`). Итоговый каталог одного запуска: `<out>/YYYY-MM-DDThh_mm_ss/`. В нём должны появиться:

### A) Манифесты/метаданные

1. `run_parameters.json` — параметры запуска (время старта, argv, конфиг, все опции CLI).
2. `manifest.json`

   * SHA256 входного ROOT
   * дата/время
   * эффективные параметры (tree, branches, chunk, mode…)
   * версии библиотек
   * время выполнения
3. `features_used.json`

   * выбранное дерево + список веток (в порядке)

### B) Таблицы

4. `branch_stats.csv`

   * per-branch: min/max/mean/std/nan_rate/median/n
5. `bin_definitions.csv` (только если mode=quantile)

   * per-branch: bin_id, left_edge, right_edge

### C) Матрицы и спектр

6. `O_matrix.npz` (если quantile, разреженная CSR)

   * матрица `O` событий × наблюдаемые (one-hot)
7. `O_matrix.npy` + `zscore_params.json` (если zscore, memmap/ndarray)
8. `corr.npz`

   * `C` (матрица корреляций)
   * `W` (матрица связности)
9. `laplacian.npz`

   * `L` (лапласиан)
   * `lambda` (собственные значения, отсортированные)
   * `eigvec_first10` (первые 10 собственных векторов, если посчитаны)

### D) Метрики и отчёт

10. `metrics.json`
11. `spectrum.csv`

    * k, lambda_k, PR_k (если доступно)
12. `report.md`

    * короткий человекочитаемый лог результатов

---

## 3) Алгоритм (строго пошагово)

### Шаг 1 — открыть ROOT и выбрать дерево

1. Открыть через `uproot.open(input_root)`.
2. Если `tree` задан в конфиге — использовать его.
3. Иначе выбрать TTree с максимальным `num_entries`.

---

### Шаг 2 — выбрать ветки (features)

Если `branches` заданы → использовать их, проверить существование.

Иначе авто-выбор:

* Просканировать первые `max_scan = 20000` событий.
* Выбрать только ветки, которые:

  * скалярные (1 значение на событие),
  * числовые (int/float),
  * `nan_rate <= 0.2`,
  * std > 0.
* Ограничить число веток до 64 (первые 64 по порядку или по минимальному nan_rate).

Записать список в `features_used.json`.

---

### Шаг 3 — первый проход статистик (chunked)

Пробежать по данным чанками:

* для каждой ветки посчитать min/max/mean/std и долю нечисел.
* отдельно оценить median по сэмплу первых 200k событий (для импутации NaN).

Сохранить `branch_stats.csv`.

---

### Шаг 4 — построить наблюдаемые Π_obs (матрица O)

Два режима:

#### Режим A: `quantile` (рекомендуется, компактнее)

1. По сэмплу первых 200k событий построить квантильные границы для каждой ветки на `bins` бинов.
2. Для каждого события:

   * взять значение ветки,
   * если NaN/inf → заменить на median ветки,
   * определить номер бина,
   * закодировать one-hot (по одной единице на ветку).
3. Результат: CSR-матрица `O` размера (N_events × d), где d = сумма бинов по всем веткам.

Сохранить:

* `bin_definitions.csv`
* `O_matrix.npz` (CSR)

#### Режим B: `zscore` (плотная матрица)

1. Для каждой ветки:

   * NaN/inf → median
   * z-score = (x-mean)/std
2. `O` хранить в memmap (`O_matrix.npy`), писать чанками.

Сохранить:

* `zscore_params.json` (mean/std/median)
* `O_matrix.npy`

---

### Шаг 5 — корреляция и матрица связности (C и W)

1. Посчитать корреляцию `C` между столбцами `O` (Pearson).

   * Если `O` разреженная one-hot → ковариация через `O.T @ O` / N.
2. Построить `W`:

   * `W = max(0, C)`
   * диагональ = 0
3. Разреживание (порядок обязателен: сначала topk, затем tau):

   * если `topk > 0` → оставить top-k на строку, симметризовать;
   * если `tau > 0` → обнулить W < tau.

Сохранить `corr.npz`.

---

### Шаг 6 — лапласиан и спектр

1. `D = diag(sum(W_row))`
2. `L = D - W`
3. Собственные значения:

   * если d ≤ 500 → полный `eigh`
   * иначе → `scipy.sparse.linalg.eigsh` для `k_eigs` наименьших
4. Отсортировать eigenvalues по возрастанию.

Сохранить `laplacian.npz`:

* `L`, `lambda`, первые 10 eigenvectors.

---

### Шаг 7 — метрики (только численные, без интерпретации)

В `metrics.json` записать:

* `N_events`
* `features_count` (ветки)
* `mode`, `bins`
* `d` (размерность наблюдаемых)
* `density_W = nnz(W) / d^2`
* `trace_L`
* `lambda_min_nonzero` (минимальное > 1e-12)
* `Neff = (sum(lambda_use)^2)/sum(lambda_use^2)`
  где `lambda_use = lambda[lambda > 1e-12]`
* `PR_k` для первых 10 мод (если eigenvectors есть):
  `PR(v) = (sum(v^2)^2)/sum(v^4)`

Сформировать `spectrum.csv` (k, lambda_k, PR_k).

---

### Шаг 8 — baseline-контроль “без корреляций”

Если `baseline=true`:

(Допускается однократная загрузка матрицы O в память для перемешивания столбцов; при очень больших N и d возможен выход за лимит 2–16 GB RAM.)

1. Разрушить корреляции при сохранении маргиналов:

   * перемешать каждый столбец `O` независимо.
2. Повторить Шаги 5–7 для baseline → `Neff0`, `lambda0`, `C0`.
3. Добавить в `metrics.json`:

   * `baseline_Neff`
   * `delta_Neff = Neff - Neff0`
   * `corr_fro_ratio = ||C||_F / ||C0||_F`

---

## 4) Критерии приёмки

Задача считается выполненной, если:

1. Скрипт работает на машине с 2–16 GB RAM (без OOM).
2. Все файлы из раздела 2 созданы.
3. `manifest.json` содержит SHA256 входного ROOT и версии библиотек.
4. Baseline вычислен и отражён в `metrics.json` и `report.md`.

---

## 5) Требуемая реализация (минимум)

* Python 3.10+
* библиотеки: `uproot`, `awkward`, `numpy`, `pandas`, `scipy`, `pyyaml`, `tqdm`
* один CLI-скрипт: `process_root.py`

### Пример CLI

```bash
python process_root.py \ - 
  --input /data/Run2012BC_DoubleMuParked_Muons.root \
  --out out \
  --mode quantile \
  --bins 16 \
  --chunk 200000 \
  --threshold-tau 0.1 \
  --topk 0 \
  --k-eigs 200
```

---

## 6) Что модель НЕ должна делать

* Не писать “что это означает” в терминах физики.
* Не подбирать параметры под “ожидаемый результат”.
* Не генерировать синтетические числа/примеры.
* Не рисовать графики по умолчанию (только если явно включено).

---

Если хочешь — я дополню ТЗ **вторым вариантом**, ещё более “железным”:

* фиксированный список веток (после твоего вывода `tree.keys()`),
* фиксированная схема биннинга и точные имена файлов,
  чтобы исполнитель вообще не принимал решений.
